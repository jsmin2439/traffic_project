#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
etl_signal_parquet.py

ë¶€ì²œì‹œ ì‹ í˜¸ë°ì´í„°(CSV, XML) â†’ Parquet
â€¢ Mac ë¦¬ì†ŒìŠ¤í¬í¬(. _*) ìë™ í•„í„°ë§
â€¢ ì œì–´ë¬¸ìÂ·ì“°ë ˆê¸°ê°’ ì—†ìŒ
â€¢ ì›ë³¸ í•„ë“œ 100% ë³´ì¡´
â€¢ ì—°êµ¬ì— ë§ëŠ” íƒ€ì… ìºìŠ¤íŒ…
usage: python etl_signal_parquet.py
"""
from __future__ import annotations
import re, glob, json
from pathlib import Path

import pandas as pd
import xmltodict
import dask.dataframe as dd
from dask import delayed
from dask.diagnostics import ProgressBar

RAW_DIR     = "0_raw/ì‹ í˜¸ë°ì´í„°"
OUT_DIR_CSV = "1_lake/signal_csv.parquet"
OUT_DIR_XML = "1_lake/signal_xml.parquet"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ì „ì²´ íŒŒì¼ ëª©ë¡ ìˆ˜ì§‘ & Mac ë¦¬ì†ŒìŠ¤í¬í¬(. _*) í•„í„°ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
all_csv = glob.glob(f"{RAW_DIR}/**/csv/*/*.csv", recursive=True)
all_xml = glob.glob(f"{RAW_DIR}/**/xml/*/*.xml", recursive=True)

def is_real_file(p: str, ext: str) -> bool:
    name = Path(p).name
    return not name.startswith("._") and name.lower().endswith(ext)

csv_paths = [p for p in all_csv if is_real_file(p, ".csv")]
xml_paths = [p for p in all_xml if is_real_file(p, ".xml")]

print(f"ğŸ” CSV íŒŒì¼ ìˆ˜: {len(csv_paths):,}")
print(f"ğŸ” XML  íŒŒì¼ ìˆ˜: {len(xml_paths):,}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ ì¶”ì¶œìš© ì •ê·œì‹
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VEH_RE_CSV = re.compile(r"([pbstlmk])\.csv$", re.I)
VEH_RE_XML = re.compile(r"([pbstlmk])\.xml$", re.I)
TS_RE_XML  = re.compile(r"(\d{14})[pbstlmk]\.xml$", re.I)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) CSV â†’ pandas.DataFrame
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_one_csv(fp: str) -> pd.DataFrame:
    p = Path(fp)
    # --- ë©”íƒ€
    route    = p.parents[2].name       # .../êµì°¨ë¡œ_XX/csv/YYYYMMDD/file.csv
    date     = int(p.parents[0].name)  # "YYYYMMDD" â†’ 20220810
    m        = VEH_RE_CSV.search(p.name)
    veh_type = m.group(1).lower() if m else "unknown"

    # --- ì›ë³¸ ì½ê¸° (ëª¨ë‘ ë¬¸ìì—´ë¡œ)
    df = pd.read_csv(fp, dtype=str)

    # --- phasepattern ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ë¹ˆê°’ ì±„ìš°ê¸°
    if "phasepattern" not in df.columns:
        df["phasepattern"] = pd.NA

    # --- ë©”íƒ€ ì¹¼ëŸ¼ ì¶”ê°€
    df["route"]    = route
    df["date"]     = date
    df["veh_type"] = veh_type
    df["path"]     = str(p)

    # --- íƒ€ì… ìºìŠ¤íŒ…
    df = df.astype({
        "interid"        : "string",
        "aringstarttime" : "string",
        "signalstate"    : "string",
        "phasepattern"   : "string",
        "route"          : "string",
        "veh_type"       : "string",
        "path"           : "string",
    })
    df["unix_time"] = pd.to_numeric(df["unix_time"], errors="coerce").astype("Int64")
    df["date"]      = df["date"].astype("Int32")

    # --- dt: unix_time â†’ 15ë¶„ ë²„í‚·, datetime64[ns]
    df["dt"] = (
        pd.to_datetime(df["unix_time"], unit="s", errors="coerce")
          .dt.floor("15min")
          .astype("datetime64[ns]")
    )
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) XML â†’ pandas.DataFrame
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_one_xml(fp: str) -> pd.DataFrame:
    p = Path(fp)
    # --- ë©”íƒ€
    route    = p.parents[2].name
    date     = int(p.parents[0].name)
    m        = VEH_RE_XML.search(p.name)
    veh_type = m.group(1).lower() if m else "unknown"
    # íƒ€ì„ìŠ¤íƒ¬í”„(YYYYMMDDHHMMSS) â†’ dt_floor
    ts_m     = TS_RE_XML.search(p.name)
    base_dt  = pd.to_datetime(ts_m.group(1), format="%Y%m%d%H%M%S") if ts_m else pd.NaT

    # --- XML íŒŒì‹±
    doc      = xmltodict.parse(p.read_text(encoding="utf-8"))
    tplogics = doc.get("tlLogics", {}).get("tlLogic", [])
    if isinstance(tplogics, dict):
        tplogics = [tplogics]

    rows: list[dict] = []
    for tl in tplogics:
        offset    = tl.get("@offset")
        prog_id   = tl.get("@programID")
        typ       = tl.get("@type")
        logic_id  = tl.get("@id")
        phases    = tl.get("phase", [])
        if isinstance(phases, dict):
            phases = [phases]
        for ph in phases:
            rows.append({
                "offset"         : offset,
                "programID"      : prog_id,
                "type"           : typ,
                "id"             : logic_id,
                "phase_duration" : ph.get("@duration"),
                "phase_state"    : ph.get("@state"),
                "route"          : route,
                "date"           : date,
                "veh_type"       : veh_type,
                "path"           : str(p),
                "dt"             : base_dt.floor("15min"),
            })

    df = pd.DataFrame(rows)

    # --- íƒ€ì… ìºìŠ¤íŒ…
    df = df.astype({
        "offset"         : "string",
        "programID"      : "Int64",
        "type"           : "string",
        "id"             : "string",
        "phase_duration" : "Int64",
        "phase_state"    : "string",
        "route"          : "string",
        "date"           : "Int32",
        "veh_type"       : "string",
        "path"           : "string",
        "dt"             : "datetime64[ns]",
    })
    return df

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) Dask â†’ Parquet ì €ì¥ ê³µí†µ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def to_parquet(delayed_fn, paths: list[str], meta: dict, out_dir: str):
    tasks = [delayed(delayed_fn)(fp) for fp in paths]
    ddf   = dd.from_delayed(tasks, meta=meta)
    ProgressBar().register()
    ddf.to_parquet(
        out_dir,
        engine="pyarrow",
        compression="zstd",
        partition_on=["route","date","veh_type"],
        write_index=False,
    )
    print(f"âœ“ Parquet ì €ì¥ ì™„ë£Œ â†’ {out_dir}")
    print("â–  ì €ì¥ëœ ì¹¼ëŸ¼:")
    print(json.dumps(list(meta.keys()), ensure_ascii=False, indent=2))


if __name__ == "__main__":
    meta_csv = {
        "interid": "string",
        "aringstarttime": "string",
        "signalstate": "string",
        "unix_time": "Int64",        # move unix_time before phasepattern
        "phasepattern": "string",
        "route": "string",
        "date": "Int32",
        "veh_type": "string",
        "path": "string",
        "dt": "datetime64[ns]",
    }
    meta_xml = {
        "offset":"string","programID":"Int64","type":"string","id":"string",
        "phase_duration":"Int64","phase_state":"string",
        "route":"string","date":"Int32","veh_type":"string",
        "path":"string","dt":"datetime64[ns]",
    }

    # 5-1) CSV â†’ Parquet
    to_parquet(
        parse_one_csv, csv_paths, meta_csv, OUT_DIR_CSV
    )
    # 5-2) XML â†’ Parquet
    to_parquet(
        parse_one_xml, xml_paths, meta_xml, OUT_DIR_XML
    )